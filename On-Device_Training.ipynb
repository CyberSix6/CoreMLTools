{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On-Device Training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the coremltools_internal APIs to convert training programs from front-end frameworks such as Tensorflow2 Keras and PyTorch to the mlprogram format for on-device training. Use on-device training technologies for Private Federated Learning (PFL) and on-device personalization.\n",
    "\n",
    "Steps to Convert and Deploy\n",
    "PyTorch Training Conversion\n",
    "TensorFlow 2 Keras Training Conversion\n",
    "Private Federated Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to Convert and DeployÔÉÅ\n",
    "\n",
    "Follow these steps to implement an end-to-end conversion and deployment pipeline for your training programs:\n",
    "\n",
    "Produce a training Core ML model by converting front-end training mode using coremltools_internal.convert() with training_mode=True (Tensorflow2 Keras and PyTorch are supported). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools_internal as ct\n",
    "#\n",
    "# Add code to obtain source_model.\n",
    "#\n",
    "model = ct.convert(source_model, training_mode=False, convert_to=\"mlprogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before deploying, test and validate your training program locally using a Python script and the Trainer and Evaluator Python-binding APIs:\n",
    "\n",
    "coremltools_internal.models.trainer.Trainer: A high-level training API that lets you update the model in a single line.\n",
    "coremltools_internal.models.evaluator.Evaluator: A low-level API that lets you evaluate each function in the training program. For example, you can initialize the model and compute the forward and backpropogation function and run the training process through your python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model using Xcode. Use the following command to produce a training model model.mlmodelc and deploy it through Xcode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coremlcompiler compile model.mlpackage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch Training Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following describes the basic model format, using TorchOptimizer, and converting the model.\n",
    "\n",
    "Basic Model Format\n",
    "\n",
    "The following is an example of training an MLP model with MSE loss using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(2, 1)\n",
    "        self.linear_2 = nn.Linear(1, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x\n",
    "\n",
    "model = LinearModel()\n",
    "\n",
    "def criterion(pred, label):\n",
    "    diff = pred - label\n",
    "    return torch.mean(diff * diff)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 3)\n",
    "\n",
    "pred = model(x)\n",
    "loss = criterion(pred, y)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, the loss function can be seperated from the model itself, which is unfortunately not allowed in the coremltools_internal training mode. The Espresso backend, which performs the training program lowering, assumes that the first model output is always the loss function, and the remaining outputs are model predictions.\n",
    "\n",
    "As the result, in the above example, you need to create a new model, which wraps the loss function along with the predictions. Note that the new model also needs to add the label as an additional input, and the original PyTorch model should be a class member of the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelToExport(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # The original model is a class member\n",
    "        self.backend = model\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.backend(x)\n",
    "        loss = criterion(x, y)\n",
    "\n",
    "        # Loss must come at first\n",
    "        return loss, x\n",
    "\n",
    "model_to_export = ModelToExport()\n",
    "optimizer = optim.SGD(model_to_export.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 3)\n",
    "\n",
    "loss, pred = model_to_export(x, y)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchOptimizer in AdvancedOptions\n",
    "\n",
    "You also need to pass the Torch optimizer information to the converter using the TorchOptimizer advanced option, which takes the torch model and the torch optimizer as inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coremltools_internal import AdvancedOptions, TorchOptimizer\n",
    "\n",
    "advanced_options = AdvancedOptions()\n",
    "torch_optimizer = TorchOptimizer(model=model_to_export, optimizer=optimizer)\n",
    "advanced_options.add_option(torch_optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion\n",
    "\n",
    "After completing the above steps, use example inputs to trace the model_to_export using torch.jit.trace(), and pass the traced model to the coremltools_internal.convert() API with training_mode=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools_internal as ct\n",
    "\n",
    "example_inputs = [x, y]\n",
    "traced_model = torch.jit.trace(model_to_export, example_inputs)\n",
    "inputs = [ct.TensorType(shape=input_.shape) for input_ in example_inputs]\n",
    "mlmodel = ct.convert(traced_model, inputs=inputs, training_mode=True, advanced_options=advanced_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
